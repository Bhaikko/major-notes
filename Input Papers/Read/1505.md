## Multiview CNN for 3D shape
```
developing view based descriptors for 3D shapes that are trainable

we present a novel CNN architecture that combines information from multiple views of a 3D shape into a single and compact shape 
descriptor offering even better recognition performance.

MCNN archi leans to recognize 3D shapes from view of the shapes using image based CNNs
```

### Introduction
```
recognition algos on 3D features such as voxel occupancy or surface curvature
buidling classifier of 3D shape from 2D image renderings of those shapes
training on fixed set of rendered view of 3D shape but only one view at test time

This descriptor is as informative for classification than full collection of view based descriptors of object.
```

### Shape descriptors
```
3D shape descriptors that work on native 3D representations
view based that describe the shape of 3D object by "how it looks" in collection of 2D projections
```

3D data descriptors

### Input Ideas
```
shapes can be represented with histograms or bag-of-features models constructed out of surface normals and curvatures [15], distances, angles, 
triangle areas or tetrahedra volumes gathered at sampled surface points [25], properties of spherical functions defined in volumetric grids [16], 
local shape diameters measured at densely sampled surface points [4], 
heat kernel signature on polygon meshes [2, 19], or 
extensions of the SIFT and SURF feature descriptors to 3D voxel grids [17].
```

### Methodology
```
multiple 2D views of object generated and aggregated representation 
combining features from multiple view is more desirable

network architecture mentioned
```

#### Multiview representation
```
phong reflection model used. Shapes uniformly scaled to fit into viewing volume
2 approaches for setting up camera
I 12 rendered views around mesh every 30 degrees
II placing cameras on isosahedron

changing lighting model does not affect output descriptor
```
```
each image in multiview passed to seperate CNN seperately, aggregated at view pooling layer then sent through 
remaining part of network
```

### References
37, 16, 5, 2, 19, 17
3D shape descriptors
### Links
```
Pretrained CNN models, data and complete source
http://vis-www.cs.umass.edu/mvcnn 
